
## [《Hands-on Machine Learning with Scikit-Learn and TensorFlow》- Codes](https://github.com/ageron/handson-ml)


1. [numpy_kafka_sentence_generate_RNN](https://github.com/davidkorea/NLP_201811/blob/master/RNN_LSTM_GRU/code/numpy_kafka_sentence_generate_RNN.md)

2. [numpy_kafka_sentence_generate_LSTM](https://github.com/davidkorea/NLP_201811/blob/master/RNN_LSTM_GRU/code/numpy_kafka_sentence_generate_LSTM.md)

    先阅读上面的RNN，理清程序脉络和思路，再看LSTM会更容易理解
    
-----


3. [tensorflow_RNN_LSTM_basic](https://github.com/davidkorea/NLP_201811/blob/master/RNN_LSTM_GRU/code/tensorflow_RNN_LSTM_basic.md)

    此处的input和 上面的input 并不一样。
    1. numpy tutorial中的input指的是一个完成的句子（包含timestep个词语）| **句子**
    2. 此处的input指的是，每个timestep的输入向量，即一个句子中的一个单词 | **单词**

4. [tensorflow_RNN_LSTM_MNIST](https://github.com/davidkorea/NLP_201811/blob/master/RNN_LSTM_GRU/code/tensorflow_RNN_LSTM_MNIST.md)

-----

5. [tensorflow_RNN_LSTM_Predict_TimeSeries](https://github.com/davidkorea/NLP_201811/blob/master/RNN_LSTM_GRU/code/tensorflow_RNN_LSTM_Predict_TimeSeries.md)

6. tutorial: [Deep RNN, GPU, dropout, LSTM](https://render.githubusercontent.com/view/ipynb?commit=5bb8d2e071852f3b5907679668705e59c0fb4a16&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616765726f6e2f68616e64736f6e2d6d6c2f356262386432653037313835326633623539303736373936363837303565353963306662346131362f31345f726563757272656e745f6e657572616c5f6e6574776f726b732e6970796e62&nwo=ageron%2Fhandson-ml&path=14_recurrent_neural_networks.ipynb&repository_id=51863547&repository_type=Repository#Deep-RNN)
