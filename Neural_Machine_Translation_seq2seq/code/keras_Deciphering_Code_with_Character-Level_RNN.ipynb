{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('../input/cipher.txt','r') as f:\n    data = f.read()\n    source = data.split('\\n')\nwith open('../input/plaintext.txt','r') as f:\n    data = f.read()\n    target = data.split('\\n')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4076a095ecfea47c407b4417ce8b47f997fe74ec"
      },
      "cell_type": "code",
      "source": "print(source[:3])\nprint(target[:3])\n# 密文-明文 一一对应",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['YMJ QNRJ NX MJW QJFXY QNPJI KWZNY , GZY YMJ GFSFSF NX RD QJFXY QNPJI .', 'MJ XFB F TQI DJQQTB YWZHP .', 'NSINF NX WFNSD IZWNSL OZSJ , FSI NY NX XTRJYNRJX BFWR NS STAJRGJW .']\n['THE LIME IS HER LEAST LIKED FRUIT , BUT THE BANANA IS MY LEAST LIKED .', 'HE SAW A OLD YELLOW TRUCK .', 'INDIA IS RAINY DURING JUNE , AND IT IS SOMETIMES WARM IN NOVEMBER .']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "084580636ee2986a151f132e2edcad4fb8b9d994"
      },
      "cell_type": "code",
      "source": "def tokenize(x):\n    tokenizer = Tokenizer(char_level=True)\n    tokenizer.fit_on_texts(x)\n    return tokenizer.texts_to_sequences(x), tokenizer # text_tokenized, text_tokenizer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9fce0cfe80940a060bfc0bfe8b6a7510aff0a585"
      },
      "cell_type": "markdown",
      "source": "1.\n```\nkeras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\n```\n- word_index, 0 is a reserved index that won't be assigned to any word.\n\n2.\n```\ntokenizer.fit_on_texts() \n```\n-  Required before using `texts_to_sequences` or `texts_to_matrix`.\n\n3.\n```\ntokenizer.texts_to_sequences()\n```\n- return a list\n\n4.\n```\ntokenizer.word_index()\n```\n- return a dict {origin word ：idx}, {' ': 1, 'e': 2, 'o': 3, 't': 4, 'i': 5} idx 0 reserved."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58adbf08f75daaab0c4c840f1d1d58107ebd3ce0"
      },
      "cell_type": "code",
      "source": "text_sentences = [\n    'The quick brown fox jumps over the lazy dog .',\n    'By Jove , my quick study of lexicography won a prize .',\n    'This is a short sentence .']\n\ntext_tokenized, text_tokenizer = tokenize(text_sentences)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de61b6641e019ce37b541755bf91e85f0214a08b"
      },
      "cell_type": "code",
      "source": "print(text_tokenizer.word_index)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{' ': 1, 'e': 2, 'o': 3, 't': 4, 'i': 5, 's': 6, 'h': 7, 'r': 8, 'y': 9, 'u': 10, 'c': 11, 'n': 12, 'a': 13, 'p': 14, '.': 15, 'q': 16, 'k': 17, 'b': 18, 'w': 19, 'f': 20, 'x': 21, 'j': 22, 'm': 23, 'v': 24, 'l': 25, 'z': 26, 'd': 27, 'g': 28, ',': 29}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f4ce0e43310c5c3c99b6172bb6abb1afc14afe5"
      },
      "cell_type": "code",
      "source": "for i, (x, tk_x) in enumerate(zip(text_sentences,text_tokenized)):\n    print('sample{}'.format(i+1))\n    print('source: {}'.format(x))\n    print('tk: {}'.format(tk_x))",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "sample1\nsource: The quick brown fox jumps over the lazy dog .\ntk: [4, 7, 2, 1, 16, 10, 5, 11, 17, 1, 18, 8, 3, 19, 12, 1, 20, 3, 21, 1, 22, 10, 23, 14, 6, 1, 3, 24, 2, 8, 1, 4, 7, 2, 1, 25, 13, 26, 9, 1, 27, 3, 28, 1, 15]\nsample2\nsource: By Jove , my quick study of lexicography won a prize .\ntk: [18, 9, 1, 22, 3, 24, 2, 1, 29, 1, 23, 9, 1, 16, 10, 5, 11, 17, 1, 6, 4, 10, 27, 9, 1, 3, 20, 1, 25, 2, 21, 5, 11, 3, 28, 8, 13, 14, 7, 9, 1, 19, 3, 12, 1, 13, 1, 14, 8, 5, 26, 2, 1, 15]\nsample3\nsource: This is a short sentence .\ntk: [4, 7, 5, 6, 1, 5, 6, 1, 13, 1, 6, 7, 3, 8, 4, 1, 6, 2, 12, 4, 2, 12, 11, 2, 1, 15]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f744ab5c2da4f9815224cdb0538bd6b92b55d987"
      },
      "cell_type": "code",
      "source": "def pad(x, length=None):\n    if length == None:\n        length = max([len(i) for i in x])\n    return pad_sequences(x, maxlen=length, padding='post')",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b1781138f51024b41c8dcdfd2bc538eecc522f9"
      },
      "cell_type": "markdown",
      "source": "```\nkeras.preprocessing.sequence.pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.0)\n```\n- padding: String, 'pre' or 'post': pad either before or after each sequence.\n- truncating: String, 'pre' or 'post': remove values from sequences larger than  maxlen, either at the beginning or at the end of the sequences.\n- value: Float or String, padding value."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45d9461af0103d5bdeae22b418aeaf8a8ea2beef"
      },
      "cell_type": "code",
      "source": "test_pad = pad(text_tokenized)\ntest_pad",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "array([[ 4,  7,  2,  1, 16, 10,  5, 11, 17,  1, 18,  8,  3, 19, 12,  1,\n        20,  3, 21,  1, 22, 10, 23, 14,  6,  1,  3, 24,  2,  8,  1,  4,\n         7,  2,  1, 25, 13, 26,  9,  1, 27,  3, 28,  1, 15,  0,  0,  0,\n         0,  0,  0,  0,  0,  0],\n       [18,  9,  1, 22,  3, 24,  2,  1, 29,  1, 23,  9,  1, 16, 10,  5,\n        11, 17,  1,  6,  4, 10, 27,  9,  1,  3, 20,  1, 25,  2, 21,  5,\n        11,  3, 28,  8, 13, 14,  7,  9,  1, 19,  3, 12,  1, 13,  1, 14,\n         8,  5, 26,  2,  1, 15],\n       [ 4,  7,  5,  6,  1,  5,  6,  1, 13,  1,  6,  7,  3,  8,  4,  1,\n         6,  2, 12,  4,  2, 12, 11,  2,  1, 15,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0]], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2abe1200a41f83d6854a27c957be74d75f5272e0"
      },
      "cell_type": "code",
      "source": "def preprocess(x, y):\n    preprocess_x, x_tk = tokenize(x) # word -> num\n    preprocess_y, y_tk = tokenize(y)\n    \n    preprocess_x = pad(preprocess_x) # pad 0\n    preprocess_y = pad(preprocess_y) # (10001, 101)\n    \n    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n    preprocess_y = preprocess_y.reshape(*(preprocess_y.shape), 1) # (10001, 101, 1)\n    # 一个sample/sentence自己一堆，一堆里面有多少个子母就有多少行，一个子母一行，一行就它自己一个num\n    return preprocess_x, preprocess_y, x_tk, y_tk",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ae07b7cd80245591ccee3a0cf73f72340f37437"
      },
      "cell_type": "code",
      "source": "pre_source, pre_target, tk_source, tk_target = preprocess(source, target)",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31fac8b56ca1c71d059bd26b9adc3fd54bb0e3da"
      },
      "cell_type": "code",
      "source": "pre_target.shape",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "(10001, 101, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "079c3a305b205302d9317dad79d5b43588167017"
      },
      "cell_type": "code",
      "source": "pre_target",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "array([[[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[14],\n        [ 3],\n        [ 1],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 2],\n        [ 7],\n        [11],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       ...,\n\n       [[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 0],\n        [ 0],\n        [ 0],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]]], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f0978d2030d91b4a3ea4ae0886606e6646d1a77"
      },
      "cell_type": "code",
      "source": "print(pre_target.reshape(10001,101))",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 5 14  3 ...  0  0  0]\n [14  3  1 ...  0  0  0]\n [ 2  7 11 ...  0  0  0]\n ...\n [ 5 14  3 ...  0  0  0]\n [ 5 14  3 ...  0  0  0]\n [ 0  0  0 ...  0  0  0]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "11ee3c0b62ddfb94a1b874249b0a8a255611f012"
      },
      "cell_type": "code",
      "source": "from keras.layers import GRU, Input, Dense, TimeDistributed\nfrom keras.models import Model\nfrom keras.layers import Activation\nfrom keras.optimizers import Adam\nfrom keras.losses import sparse_categorical_crossentropy",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6172055b61adace02d1c5bf089588a3f2610fb04"
      },
      "cell_type": "code",
      "source": "def simple_model(input_shape, output_sequence_length, source_vocab_size, target_vocab_size):\n              #（ (10001, 101, 1), 101, 32, 32）\n    lr = 1e-3\n    input_seq = Input(input_shape[1:]) \n    # (101, 1), 一列， 每一行代表一个子母，作为一个timestep的输入\n    # 不能直接使用preprocess_x（10001，101），这样的形式不能作为输入\n    rnn = GRU(64, return_sequences=True)(input_seq)\n    logits = TimeDistributed(Dense(target_vocab_size))(rnn)\n    \n    model = Model(input_seq, Activation('softmax')(logits))\n    model.compile(loss=sparse_categorical_crossentropy, \n                  optimizer=Adam(lr),\n                  metrics=['accuracy'])\n    return model",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64ddb65a891b1db667b5a77cba38faa86d169eec"
      },
      "cell_type": "code",
      "source": "pre_source.shape",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "(10001, 101)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "968de7bab62572407b01fe5af6e25878f443dfdf"
      },
      "cell_type": "code",
      "source": "pre_target.shape",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "(10001, 101, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a4e40f2bc31cc1d6f3597888b96a30f876f7322c"
      },
      "cell_type": "code",
      "source": "pre_target.shape[1]",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "101"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "56e531184779491c9c4570c203b6ec4a591535a6"
      },
      "cell_type": "code",
      "source": "pre_target.shape[-2]",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "101"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c35721ff7d06c20bd98d4242962c33f8ae3fdc0"
      },
      "cell_type": "code",
      "source": "# Reshaping the input to work with a basic RNN\ntmp_x = pad(pre_source, pre_target.shape[1]) # 输入句子pad成和输出句子一样的长度，此处不必要\ntmp_x = tmp_x.reshape((-1, pre_target.shape[-2], 1)) # 和前面reshape preprocess_y的操作一样\nprint(pre_source.shape,' -> ',tmp_x.shape)\nprint(tmp_x.shape[1:])",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(10001, 101)  ->  (10001, 101, 1)\n(101, 1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "65ad8fb04ed68e0bbae213acc0c96efbf0b5967f"
      },
      "cell_type": "code",
      "source": "tmp_x",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "array([[[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[14],\n        [ 3],\n        [ 1],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 2],\n        [ 7],\n        [11],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       ...,\n\n       [[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 5],\n        [14],\n        [ 3],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]],\n\n       [[ 0],\n        [ 0],\n        [ 0],\n        ...,\n        [ 0],\n        [ 0],\n        [ 0]]], dtype=int32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a2ba6099eb8fb5166fc2c0c3dd2126eed285e093"
      },
      "cell_type": "code",
      "source": "tmp_x[:1].shape # tmp_x[:1, :, :]， 选择第一个元素，即第一个sample/sentence",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": "(1, 101, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ccd1bbdd9015ffe0ae9b5092e3457ba296cbb7c7"
      },
      "cell_type": "code",
      "source": "# Train the neural network\nsimple_rnn_model = simple_model(\n    tmp_x.shape, # (10001, 101, 1)\n    pre_target.shape[1], # 101 of (10001, 101, 1)\n    len(tk_source.word_index)+1, # 31+1 = 32\n    len(tk_target.word_index)+1)",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "557574df791aba2ce82139c9c0f4b17973a530d5"
      },
      "cell_type": "code",
      "source": "simple_rnn_model.fit(tmp_x, pre_target, batch_size=32, epochs=5, validation_split=0.2)",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 8000 samples, validate on 2001 samples\nEpoch 1/5\n8000/8000 [==============================] - 19s 2ms/step - loss: 1.5188 - acc: 0.5932 - val_loss: 0.8733 - val_acc: 0.7475\nEpoch 2/5\n8000/8000 [==============================] - 18s 2ms/step - loss: 0.6642 - acc: 0.8252 - val_loss: 0.4967 - val_acc: 0.8822\nEpoch 3/5\n8000/8000 [==============================] - 18s 2ms/step - loss: 0.3878 - acc: 0.9104 - val_loss: 0.3038 - val_acc: 0.9293\nEpoch 4/5\n8000/8000 [==============================] - 18s 2ms/step - loss: 0.2495 - acc: 0.9459 - val_loss: 0.2056 - val_acc: 0.9581\nEpoch 5/5\n8000/8000 [==============================] - 22s 3ms/step - loss: 0.1753 - acc: 0.9652 - val_loss: 0.1490 - val_acc: 0.9704\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f2f937fb128>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57dff93230397d76ff89fc8ac11f478f10614db6"
      },
      "cell_type": "code",
      "source": "def logits_to_text(logits, tokenizer):\n    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n    index_to_words[0] = '<PAD>'\n\n    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n\nprint('`logits_to_text` function loaded.')\n\nprint(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], tk_target))\n# tmp_x[:1] = tmp_x[:1, :, :]",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "`logits_to_text` function loaded.\nt h e   l i m e   i s   h e r   l e a s t   l i k e d   f r u i t   ,   b u t   t h e   g a n a n a   i s   m y   l e a s t   l i k e d   . <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9b82e6a91031f62e1775fc6d38ec08c57fb04a39"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e11e04d0e061ef11fe8b7ab7df14907cc71108e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c1cc1c9d4c76ed8a6276b9b7e0952b695743d587"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0dd79095c4a6e8773a32b37a0139fada7a202986"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bb0824ed3a64b3da9d2c7bc84e5f6a4a34c12f6f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aaebf0799e30ce88b80cd93abbe832e0bfc93f21"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e5e7908457e7060513aa41dae6f18e2aba34cf2"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "401a472132cfb0a0e9b50163644f0cc9cb293459"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}